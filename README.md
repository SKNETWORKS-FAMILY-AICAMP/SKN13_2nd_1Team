# ✂️ 미용실 고객 노쇼(No-Show) 예측 프로젝트

## 1. 팀명 및 소개

- **팀명**: 브레드 이발소 ✂️🍞
- **팀원**: 고범석, 김동욱, 안수민

  | ![](./images/브레드이발소%20빵.jpeg) | ![](./images/브레드이발소%20버터와플.jpeg) | ![](./images/브레드이발소%20아이스크림1.jpeg) |
  | ------------------------------------ | ------------------------------------------ | --------------------------------------------- |
  | 고범석                               | 김동욱                                     | 안수민                                        |

---

## 2. 프로젝트 개요

> 고객의 예약 정보를 기반으로 **노쇼 가능성을 예측**하고,
> 노쇼 현상에 대한 경각심을 깨우쳐 주며
> 미용실 운영 효율화를 위한 **사전 대응 방안을 제안**하는 프로젝트
>
> **노쇼**란? 예약했지만 취소한다는 연락 없이 예약 장소에 나타나지 않는 행위

---

## 3. 배경 및 목표

![기사1](./images/기사1.png)
![기사2](./images/기사2.png)

- 대부분의 미용실에서 **고객 노쇼로 인한 손실**이 발생하고 있다.
- 노쇼 가능성이 높은 고객의 특성을 파악하고 예측이 가능하다면, 노쇼 방지를 위한 대책 마련이 가능하다.
- 프로젝트 목표:
  - **노쇼 예측 모델 개발**
  - **영향력 높은 고객 특성 분석**
  - **대응 전략 제안**

---

## 4. 사용 데이터 설명

- **출처**: Kaggle (Hair Salon No-Show Dataset) https://www.kaggle.com/datasets/frederickferguson/hair-salon-no-show-data-set/data
- **샘플 수**: 실제 미용실에서 5개월 간의 예약 1952건
- **컬럼 수**: 20개
- **변수 유형**:
  - 범주형 변수: 요일, 시간대, 서비스 종류, 담당자 등
  - 수치형 변수: 누적 방문 횟수, 누적 결제 금액 등
- **타깃 데이터**: noshow 컬럼 데이터

---

## 5. 기술 스택

- **언어**: Python
- **주요 라이브러리**:
  - 데이터 처리: pandas, numpy
  - 시각화: matplotlib, streamlit
  - 모델링: scikit-learn

---

## 6. 프로젝트 폴더 구조

```
📁SKN13_2nd_1Team
├─ app
│  ├─ app.py
│  └─ pages
├─ dataset
│  ├─ processed
│  └─ raw
├─ images
├─ models
│  ├─ knn
│  ├─ logistic_regression
│  ├─ random_forest
│  ├─ SVM
│  │  └─ Evaluation Metrics
│  └─ xgboost
│     ├─ Evaluation Metrics
├─ README.md
├─ utils
└─ 최종산출물

```

---

## 7. EDA (탐색적 분석)

### ✅ 전체 노쇼 비율

- 전체 고객 중 **노쇼(No-Show) 비율은 매우 낮음**
  → **심각한 클래스 불균형**이 존재함
  → 모델이 모두 '음성'이라고 예측해도 **정확도가 높게 나오는 착시** 발생 가능성 있음
  → **SMOTE 오버샘플링**과 같은 보정 기법 필요성 도출

---

### ✅ 요일별 노쇼 경향

![요일별](./images/요일별노쇼.png)

- **일요일**에 노쇼 비율이 높음
- 전체적으로 요일별로 약간의 편차는 있으나 극단적이지는 않음

---

### ✅ 시간대별 노쇼 경향

![시간대별](./images/시간대별노쇼.png)

- **오후(afternoon)** 에 가장 높음
- 오전(morning)에 비해 아침 시간 노쇼가 두드러짐

---

### ✅ 누적 노쇼 횟수와 실제 노쇼율의 관계

![요일별](./images/누적노쇼.png)

- **누적 노쇼 횟수가 많을수록 실제 노쇼 확률도 증가**
  - 누적 0회 → 노쇼율 매우 낮음
  - 누적 2~3회 → 점진적 증가
  - **누적 4회 이상 고객**의 노쇼율은 평균 대비 **3배 이상**

---

### ✅ 첫 방문 여부와 예측 가능성

- `last_` 계열 컬럼에 결측치가 다수 존재, 이는 **첫 방문 고객**으로 판단됨
  → 모델 학습 큰 영향을 줄 수 있다고 판단했기에 관련된 **파생 변수** 생성 고려
- 첫 방문 고객의 노쇼 경향은 후속 분석 및 모델링에서 주요 고려 대상임

---

## 8. 데이터 전처리

- **결측치 처리**:
  - `last_` 계열 변수: `Unknown`으로 채움 (첫 방문이라는 유의미한 정보)
  - 예약 정보 누락: 최빈값으로 채움 (기록 누락)
- **파생 변수 생성**:
  - `first_visit`: 첫 방문인지 여부
  - `is_revisit_30days`: 한 달 내 재방문인지 여부
- **범주형 변수 인코딩**:
  - Label Encoding: XGBoost, KNN
  - One Hot Encoding: LogisticRegression, SVM, RandomForest
- **수치형 변수 스케일링**: StandardScaler
- **오버 샘플링**:
  - SMOTE: XGBoost, KNN, LogisticRegression, RandomForest
- **데이터 분할**: 8:2 비율, GridSearchCV 내에서 5-Fold(또는 3-Fold) CV 수행

---

## 9. 평가 지표 선정

- **F1 Score**
  - 데이터 간 불균형이 있기 때문에, precision과 recall의 조화 평균인 f1 score는 중요한 평가 지표임
- **정밀도 (Precision)**
  - 양성 클래스를 정확하게 예측하기 위함
- **재현율 (Recall)**
  - 노쇼를 놓치지 않고 잡아내는 것이 서비스 운영 측면에서 중요하다고 판단
- 정확도 (Accuracy)
- 혼동 행렬
- PR Curve / AP Score
- ROC Curve / AUC Score

---

## 10. 모델 선정

| 모델                | 특징                      | 선정 이유                                                                                                                                                                                                                                        |
| ------------------- | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Logistic Regression | 기본 분류 성능, 해석 용이 | - 이진 분류에 특화된 모델이며 각 특성이 결과에 어떤 영향을 미치는지 명확하게 파악 가능하다. <br> - L1, L2 정규화 옵션으로 일반화 성능 향상이 가능하다.                                                                                           |
| SVM                 | 마진 기반 분류            | - 사용하는 데이터셋이 feature 수가 많고 크기가 작은 데이터셋인데, SVM은 이 경우에 강한 성능을 보이기 때문이다.                                                                                                                                   |
| XGBoost             | 성능 우수, 트리 기반      | - XGBoost는 부스팅 알고리즘으로 앙상블 기법을 사용하며, 다양한 데이터 유형과 복잡한 패턴에 대해 강력한 성능을 보일 수 있다. <br> - 클래스 불균형 문제를 다룰 수 있는 가중치 조정과 샘플링 기법을 제공하여 불균형 데이터셋에도 잘 대응할 수 있다. |
| Random Forest       | 트리 기반                 | - 여러 결정트리를 앙상블하여 과적합을 줄일 수 있다.<br> - 각 피처의 중요도를 확인할 수 있어 인사이트 도출에 유리하다.                                                                                                                            |
| KNN                 | 직관적                    | -고객 특성에 따라 명확한 군집 또는 패턴이 존재하는 경우, 높은 분류 정확도 기대 가능하다. <br> - 구조가 단순하고 직관적이기 때문에 다른 복잡한 모델과의 성능 비교 기준선 역할 가능하다.                                                           |

---

## 11. 자동화 및 튜닝 전략

- **Pipeline**으로 전처리 + 모델 학습 흐름 구성
- **GridSearchCV**로 튜닝 자동화, 최적의 파라미터 탐색
- 최적의 Threshold 추출
  - Recall이 가장 중요한 평가 지표였기 때문에 Threshold 값을 낮추는 방향으로 조정했다.
  - 너무 작은 Threshold 값은 Recall 값을 1로 고정시키기 때문에 최소 0.3으로 제한을 두었다.

---

## 12. 분석 결과 해석

![그래프](./images/feature_importance.png)

- 노쇼 고객은 주로 `STYLE` 서비스 / `일요일 점심`에 예약했다.
- XGBoost 모델이 가장 높은 성능을 보였다 (Recall 기준)
- 최적의 XGBoost 모델에서 학습하는 데 가장 중요하게 사용된 특성이 '예약 시간대'임을 알 수 있다.
- 평가 지표에 따라 최적 모델이 달라질 수 있다.

---

## 13. 결과 요약

| 모델                | F1 Score | Recall | Precision |
| ------------------- | -------- | ------ | --------- |
| Logistic Regression | 0.37     | 0.62   | 0.26      |
| SVM                 | 0.23     | 0.71   | 0.14      |
| XGBoost             | 0.32     | 0.78   | 0.14      |
| Random Forest       | 0.37     | 0.55   | 0.28      |
| KNN                 | 0.34     | 0.4    | 0.3       |

---

## 14. 한 줄 회고

> 고범석: “데이터는 노쇼를 기억하고 있었다.” 두 번째 프로젝트를 진행하며 확실히 첫번째 프로젝트 보다 팀원간의 의사소통 및 협업에서 더 수월하게 진행됐다. 그간 배웠던 머신러닝 모델에 새로운 데이터를 적용하여 학습 및 추론, 검증 과정을 거치며 머신러닝에 대해 좀 더 깊은 이해가 되었다. 머신러닝 프로젝트에서 데이터의 크기, 정제 정도 등 데이터 자체의 중요성에 대해 크게 깨닳았고, 머신러닝 모델 자체보다 모델의 하이퍼 파라미터들을 어떻게 다루는지가 중요하는 것을 느낀 프로젝트였다.<br>
> 김동욱: 이번 프로젝트는 다양한 머신러닝 모델을 학습한 내용을 실제로 적용해보며, 이론과 실무를 연결할 수 있었던 뜻깊은 경험이었다. 그동안 추상적으로만 이해하고 있던 개념들이 프로젝트를 진행하면서 점차 구체화됨을 느꼈다. 특히 다양한 평가지표를 직접 비교, 분석하면서 모델의 성능을 입체적으로 이해할 수 있었다. 이 과정에서 모델링도 중요하지만 먼저 데이터를 다루는 전처리 단계가 얼마나 중요한지를 체감하며, 데이터 분석 전반에 대한 이해도 또한 함께 높일 수 있었다.<br>
> 안수민: 예측을 넘어 운영 개선을 이끄는 인사이트 도출이 가장 큰 수확이었다.

---
