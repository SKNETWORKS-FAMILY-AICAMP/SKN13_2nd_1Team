import shap
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from xgboost import XGBClassifier
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import roc_auc_score, roc_curve, f1_score, precision_recall_curve

# ë°ì´í„° ë¡œë“œ
hair_salon_data = pd.read_csv('dataset/processed/hair_salon_data.csv')

# ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ë³„ë¡œ LabelEncoder ë”°ë¡œ ì ìš©
categorical_cols = ['book_tod', 'book_dow', 'book_category', 'book_staff', 
                    'last_staff', 'last_dow', 'last_tod']
for col in categorical_cols:
    le = LabelEncoder()
    hair_salon_data[col] = le.fit_transform(hair_salon_data[col].astype(str))

# í”¼ì²˜ ì»¬ëŸ¼ ì •ì˜
feature_cols = [
    *categorical_cols,
    'last_receipt_tot', 'last_prod_flag', 'last_cumrev', 'last_cumbook', 
    'last_cumstyle', 'last_cumcolor', 'last_cumprod', 'last_cumcancel', 
    'last_cumnoshow', 'recency', 'first_visit'
]

X = hair_salon_data[feature_cols].values
y = hair_salon_data['noshow'].values

# í´ë˜ìŠ¤ ë¹„ìœ¨ ê³„ì‚° í›„ scale_pos_weight ê³„ì‚°
neg, pos = np.bincount(y)
scale_pos_weight = neg / pos
print(f"Class ratio (neg:pos): {neg}:{pos} => scale_pos_weight: {scale_pos_weight:.2f}")

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# í•˜ì´í¼íŒŒë¼ë¯¸í„° (ì˜ˆì‹œ)
best_params = {
    'colsample_bytree': 0.8,
    'learning_rate': 0.05,
    'max_depth': 5,
    'min_child_weight': 3,
    'n_estimators': 100,
    'subsample': 0.8
}

# ëª¨ë¸ ìƒì„±
xgb_best = XGBClassifier(
    eval_metric='logloss',
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    **best_params
)

# êµì°¨ê²€ì¦ F1 ì ìˆ˜ ê³„ì‚° ë° ì¶œë ¥ (í•™ìŠµ ì „ì—)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(xgb_best, X_train, y_train, scoring='f1', cv=cv)
print(f"ğŸ“Š 5-Fold F1 Scores: {scores}")
print(f"âœ… í‰ê·  F1 Score: {scores.mean():.4f}")

# ëª¨ë¸ í•™ìŠµ
xgb_best.fit(X_train, y_train)

# í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ë° í‰ê°€
y_pred = xgb_best.predict(X_test)
y_proba = xgb_best.predict_proba(X_test)[:, 1]

print("===== Test Set Classification Report =====")
print(classification_report(y_test, y_pred, digits=4))
print("Accuracy: ", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:   ", recall_score(y_test, y_pred))
print("F1 Score: ", f1_score(y_test, y_pred))
print("ROC AUC:  ", roc_auc_score(y_test, y_proba))

# í˜¼ë™í–‰ë ¬ ì‹œê°í™”
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_best.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix (Test Set)")
plt.show()

# SHAP í•´ì„
explainer = shap.Explainer(xgb_best)
shap_values = explainer(X_test)

# SHAP summary plot ì €ì¥ (í™”ë©´ ì¶œë ¥ ëŒ€ì‹ )
shap.summary_plot(shap_values, X_test, feature_names=feature_cols, show=False)
plt.savefig('shap_summary_scatter (ë³€ìˆ˜ ì œê±°).png')
plt.close()

shap.summary_plot(shap_values, X_test, feature_names=feature_cols, plot_type='bar', show=False)
plt.savefig('shap_summary_bar (ë³€ìˆ˜ ì œê±°).png')
plt.close()

# PR Curve ê·¸ë¦¬ê¸°
from sklearn.metrics import precision_recall_curve, auc
probs = xgb_best.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, probs)
pr_auc = auc(recall, precision)

plt.figure(figsize=(8, 6))
plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.4f}')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.grid()
plt.savefig('PR Curve (ë³€ìˆ˜ ì œê±°)')
plt.close()

